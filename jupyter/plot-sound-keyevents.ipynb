{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import mysql.connector as mysql\n",
    "import bokeh.plotting\n",
    "import bokeh.models\n",
    "import bokeh.io\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import statistics\n",
    "from scipy.signal import find_peaks\n",
    "import sklearn.cluster\n",
    "from itertools import groupby\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics.cluster import homogeneity_score, normalized_mutual_info_score, homogeneity_completeness_v_measure\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sklearn.mixture\n",
    "from tqdm import tqdm\n",
    "\n",
    "AUDIO_FILES_DIR='../web/data/videos'\n",
    "\n",
    "datetimeTickFormatter = bokeh.models.DatetimeTickFormatter(\n",
    "    microseconds = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    milliseconds = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    seconds = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    minsec = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    minutes = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    hourmin = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    hours = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    days = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    months = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    years = ['%d-%m    %H:%M:%S.%3N'])\n",
    "\n",
    "def getCombinedWavs(directory, use_directory_starttime=True):\n",
    "    nr = 0\n",
    "    sr = None\n",
    "    y = None\n",
    "    files = os.listdir(f'{AUDIO_FILES_DIR}/{directory}')\n",
    "    files.sort()\n",
    "    last_endtime = None\n",
    "    total_gap = 0\n",
    "    for filename in files:\n",
    "        fullfilename = f'{AUDIO_FILES_DIR}/{directory}/{filename}'\n",
    "        y_part, sr_part = librosa.load(fullfilename, sr=None)\n",
    "        \n",
    "        file_end = int(re.search(\"^\\d*-(\\d*)\\.wav\", filename).group(1))\n",
    "        file_start = file_end - int(len(y_part) * 1000 / sr_part)\n",
    "        if sr == None:\n",
    "            sr = sr_part\n",
    "            y = y_part\n",
    "            end = int(re.search(\"^\\d*-(\\d*)\\.wav\", files[0]).group(1))\n",
    "            if use_directory_starttime:\n",
    "                unixtime_start = int(re.search(\".*-(\\d*)\", directory).group(1))\n",
    "            else:\n",
    "                unixtime_start = file_start            \n",
    "        else:\n",
    "            if sr != sr_part:\n",
    "                raise Exception(\"Sampling rate mismatch\")\n",
    "            y = np.concatenate([y, y_part])\n",
    "        nr += 1\n",
    "        if last_endtime == None:\n",
    "            print (f'part {\"%3d\" % nr}, {\"%7d\" % len(y_part)} samples from unixtime {file_start} to {file_end}.')\n",
    "        else:\n",
    "            gap = file_start - last_endtime\n",
    "            total_gap += gap\n",
    "            print (f'part {\"%3d\" % nr}, {\"%7d\" % len(y_part)} samples from unixtime {file_start} to {file_end}. Gap: {gap}. Total gap: {total_gap}')\n",
    "        last_endtime = file_end\n",
    "        \n",
    "    unixtime_end = int(unixtime_start + len(y) * 1000 / sr)\n",
    "    print (f'total:    {\"%7d\" % len(y)} samples from unixtime {unixtime_start} to {unixtime_end}')\n",
    "    print (f'Read {nr} parts from {directory}. {y.shape[0]} samples: {\"%.1f\" % (y.shape[0]/sr)} seconds at {sr} samples/sec, starting at unixtime {unixtime_start}')\n",
    "    return y, sr, unixtime_start\n",
    "\n",
    "def queryDb(query, args=()):\n",
    "    try:\n",
    "        conn = mysql.connect(user=\"root\",\n",
    "                             password=\"1234\",\n",
    "                             host=\"localhost\",\n",
    "                             port=3306,\n",
    "                             database=\"imagedescription\")\n",
    "    except mysql.Error as e:\n",
    "        print(f\"Error connecting to MariaDB Platform: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Get Cursor\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(query, args)\n",
    "    data = [x for x in cur]\n",
    "    cur.close()\n",
    "    return data\n",
    "\n",
    "def getSteps(s):\n",
    "    s = list(s)\n",
    "    return [cur-prev for (cur, prev) in zip(s, [s[0]]+s)]\n",
    "\n",
    "def getAllTraceEvents(directory):\n",
    "    starttime=int(re.search(\".*-(\\d*)\", directory).group(1))\n",
    "    return queryDb(f\"\"\"select time, unix_time, type, data from logger_traces where uuid = (select uuid from logger_traces lt where type='startaudio' and data like '%{starttime}') order by id\"\"\", ())\n",
    "\n",
    "def getData(directory, use_directory_starttime=True):\n",
    "    wav, sr, starttime_file = getCombinedWavs(directory, use_directory_starttime)\n",
    "    audio_length_ms = int(len(wav) / sr * 1000)\n",
    "\n",
    "    print (f'Recording starts at unix time {starttime_file} and lasts until {starttime_file + audio_length_ms}')\n",
    "\n",
    "    events = getAllTraceEvents(directory)\n",
    "\n",
    "    up_events = [x for x in events if x[2]=='keyup']\n",
    "    down_events = [x for x in events if x[2]=='keydown']\n",
    "    recorder_mark_events = [x for x in events if x[2]=='recorder-mark']\n",
    "\n",
    "    first_mark_at = recorder_mark_events[0][1]\n",
    "    first_mark_samples = recorder_mark_events[0][3]\n",
    "    starttime_recorder_mark_event = int(first_mark_at-(first_mark_samples*1000/sr))\n",
    "    starttime_recorder_start_event = [x for x in events if x[2]=='recorder-start'][0][1]\n",
    "    starttime_startaudio_event = [x for x in events if x[2]=='startaudio'][0][1]\n",
    "    \n",
    "    print(f'Read {len(up_events)} keyup events, {len(down_events)} keydown events, and {len(recorder_mark_events)} recorder-mark events.')\n",
    "\n",
    "    return {\n",
    "        'wav': wav,\n",
    "        'sr': sr,\n",
    "        'starttime_file': starttime_file,\n",
    "        'starttime_recorder_mark_event': starttime_recorder_mark_event,\n",
    "        'starttime_recorder_start_event': starttime_recorder_start_event,\n",
    "        'starttime_startaudio_event': starttime_startaudio_event,\n",
    "        'up_events': up_events,\n",
    "        'down_events': down_events,\n",
    "        'recorder_mark_events': recorder_mark_events,\n",
    "        'events': events\n",
    "    }\n",
    "\n",
    "def plotMatplotlib(data):\n",
    "    wav=data['wav']\n",
    "    sr=data['sr']\n",
    "    starttime_file=data['starttime_file']\n",
    "    up_events=data['up_events']\n",
    "    down_events=data['down_events']\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.ylim((0,0.02))\n",
    "    librosa.display.waveplot(wav, sr=sr, alpha=0.1)\n",
    "    plt.scatter([(x[1]-starttime_file)/1000 for x in down_events], [0 for _ in down_events])\n",
    "    plt.scatter([(x[1]-starttime_file)/1000 for x in up_events], [0.01 for _ in up_events])\n",
    "\n",
    "def plotBokeh(data, adjust_ms=0, whichWav='wav'):\n",
    "    wav=data[whichWav]\n",
    "    sr=data['sr']\n",
    "    starttime_file=data['starttime_file']\n",
    "    up_events=data['up_events']\n",
    "    down_events=data['down_events']\n",
    "    \n",
    "    s_sound = pd.Series(data=wav, index=range(len(wav)))\n",
    "    df_sound = pd.DataFrame(s_sound)\n",
    "    df_sound.reset_index(inplace=True)\n",
    "    df_sound.columns = ['Index', 'wav']\n",
    "    df_sound['unixtime'] = df_sound['Index'].apply(lambda x: starttime_file + x * 1000 / sr)\n",
    "    df_sound['time'] = df_sound['Index'].apply(lambda x: datetime.datetime.utcfromtimestamp(int(x / 1000)))\n",
    "\n",
    "    bokeh.io.output_notebook()\n",
    "    p = bokeh.plotting.figure()\n",
    "    p.xaxis.formatter = datetimeTickFormatter\n",
    "    p.xaxis.major_label_orientation = math.pi/2\n",
    "    p.line(x='unixtime', y='wav', source=df_sound)\n",
    "    \n",
    "    def plotEvents(events, colour=\"black\", y_offset=0):\n",
    "        df = pd.DataFrame()\n",
    "        df['x'] = [e[1]+adjust_ms for e  in events]\n",
    "        df['y'] = [0.015]*len(events)\n",
    "        df['text'] = [e[3][3:] if e[3].startswith('Key') else e[3] for e in events]\n",
    "        source = bokeh.models.ColumnDataSource(df)\n",
    "\n",
    "        p.scatter(x='x', y='y', source=source, size=10, color=colour, alpha=0.5)\n",
    "        p.add_layout(bokeh.models.LabelSet(x='x', y='y', text='text', source=source, x_offset=5, y_offset=y_offset, render_mode='canvas', angle=math.pi/2, text_color=colour))\n",
    "    \n",
    "    plotEvents(down_events, \"green\", 20)\n",
    "    plotEvents(up_events, \"red\", -120)\n",
    "       \n",
    "    bokeh.plotting.show(p)\n",
    "    \n",
    "def diffPeekAmplAndKeyDown(directory):\n",
    "    data = getData(directory)\n",
    "    down_event = data['down_events'][0][1]\n",
    "    max_index = np.argmax(data['wav'])\n",
    "    max_time = data['starttime_file'] + int(max_index * 1000 / data['sr'])\n",
    "    print (f'{directory} max ampl at {max_time}, keydown at {down_event}, difference {max_time-down_event}')\n",
    "\n",
    "def getDataSubset(data, offset_ms, length_ms=2000):\n",
    "    sr = data['sr']\n",
    "    starttime  = data['starttime_file'] + offset_ms\n",
    "    subset_wav = data['wav'][int(offset_ms*sr/1000):int((offset_ms+length_ms)*sr/1000)]\n",
    "    if 'adjusted_wav' in data.keys():\n",
    "        subset_adjusted_wav = data['adjusted_wav'][int(offset_ms*sr/1000):int((offset_ms+length_ms)*sr/1000)]\n",
    "    else:\n",
    "        subset_adjusted_wav = None\n",
    "    subset_up_events   = [e for e in data['up_events']   if starttime < e[1] and e[1] < (starttime+length_ms)]\n",
    "    subset_down_events = [e for e in data['down_events'] if starttime < e[1] and e[1] < (starttime+length_ms)]\n",
    "    \n",
    "    return {\n",
    "        'wav': subset_wav,\n",
    "        'adjusted_wav': subset_adjusted_wav,\n",
    "        'sr': sr,\n",
    "        'starttime_file': starttime,\n",
    "        'up_events': subset_up_events,\n",
    "        'down_events': subset_down_events\n",
    "    }\n",
    "    \n",
    "def aap(x, adjust_ms=0):\n",
    "    data=getData(f'../web/data/videos/{x}')\n",
    "    plotBokeh(data, adjust_ms=adjust_ms)\n",
    "    \n",
    "    wav=data['wav']\n",
    "    sr=data['sr']\n",
    "    s=librosa.stft(y=wav, hop_length=int(sr/1000))\n",
    "    data['wav'] = abs(s.sum(axis=0))\n",
    "    data['sr'] = 1000\n",
    "    plotBokeh(data)\n",
    "\n",
    "\n",
    "def moving_ranges(data, context):\n",
    "    data2 = list(data)\n",
    "    data3 = [data2[0]]*(context) + data2\n",
    "    return [data3[i:i+1+context] for i in range(len(data2))]\n",
    "def moving_ranges_f(data, context, f):\n",
    "    ranges = moving_ranges(data, context)\n",
    "    return [f(x) for x in ranges]\n",
    "def moving_average(x, context):\n",
    "    return moving_ranges_f(x, context, statistics.mean)\n",
    "def moving_var(x, context):\n",
    "    return moving_ranges_f(x, context, lambda r: max(r)-min(r))\n",
    "\n",
    "## Calculate where to add dummy values to compensate for occassionally dropped samples and keep the audio in sync with database\n",
    "\n",
    "# The difference between the number of samples in the data, and the expected number based on sampling rate and during\n",
    "# varies over time. Samples don't get delivered exactly on time, but usually the difference stays within a clear bound.\n",
    "#\n",
    "# Two things may occur that break this pattern:\n",
    "#  1) occassionally some samples get queued up and delivered late, so we see a temporary increase in the difference which quickly gets corrected when the samples do arrive\n",
    "#  2) on other occassions samples really get dropped and we see the difference increase permanently\n",
    "#\n",
    "# To keep keystrokes in sync, the first case doesn't matter since later we will only use the samples and don't care when they were received,\n",
    "# but for the second case we want to insert some dummy samples to make sure the samples after that stay in sync.\n",
    "\n",
    "\n",
    "def getDroppedSamplesTimeAndLengthForDirectory(directory, showGraph=False):\n",
    "    return getDroppedSamplesTimeAndLength(getData(directory), showGraph)\n",
    "\n",
    "def getDroppedSamplesTimeAndLength(data, showGraph=False):\n",
    "    CONTEXT=4\n",
    "       \n",
    "    # Transform the list of mark events into a dataframe with a column, samplesDiff,\n",
    "    # indicating the difference between the actual number of samples and the expected\n",
    "    # number based on sampling rate and time since the start of the recording.\n",
    "    timeAndBufferSize = [(x[1], x[3]) for x in data['recorder_mark_events']]\n",
    "    starttime=timeAndBufferSize[0][0]\n",
    "    startsize=timeAndBufferSize[0][1]\n",
    "    times = [t for (t, s) in timeAndBufferSize]\n",
    "    samplesDiff = [(s-startsize)-((t-starttime)*data['sr']/1000) for (t, s) in timeAndBufferSize]\n",
    "    msSinceLastSample=getSteps(times)\n",
    "    df = pd.DataFrame()\n",
    "    df['time']=times\n",
    "    df['samplesDiff']=samplesDiff\n",
    "    df['msSinceLastSample']=msSinceLastSample    \n",
    "    \n",
    "    # First find the peaks and dips in the oscilating sample difference\n",
    "    peaks = find_peaks(df['samplesDiff'])[0]\n",
    "    dips = find_peaks([-x for x in df['samplesDiff']])[0]\n",
    "    dips_and_peaks = np.concatenate((dips, peaks))\n",
    "    dips_and_peaks.sort()\n",
    "    df_dips_peaks = df.iloc[dips_and_peaks].copy()\n",
    "    df_dips_peaks['dippeak'] = ['dip' if x in dips else 'peak' for x in df_dips_peaks.index]\n",
    "    df_dips_peaks['samplesDiffMV'] = moving_var(df_dips_peaks['samplesDiff'], CONTEXT)\n",
    "\n",
    "    # Filter out these outliers based on the max difference in the samplesDiff column over a trailing window of CONTEXT samples\n",
    "    median_moving_var = statistics.median(moving_var(df_dips_peaks['samplesDiff'], CONTEXT))    \n",
    "    not_outliers = [i for i in range(len(dips_and_peaks)-1)\n",
    "                    if df_dips_peaks['samplesDiff'].iloc[i+1] - df_dips_peaks['samplesDiff'].iloc[i] < 1.5*median_moving_var]\n",
    "    df_dips_peaks_clean = df_dips_peaks.iloc[not_outliers].copy()\n",
    "    # recalculate this since it will have changed after removing the outliers\n",
    "    df_dips_peaks_clean['samplesDiffMV'] = moving_var(df_dips_peaks_clean['samplesDiff'], CONTEXT)     \n",
    "\n",
    "    # We now want to find the segments of stable data, and calculate the number samples lost by comparing the average value for peaks and dips in two blocks\n",
    "    # The variation in sample difference is quite stable within a block, so we mark points where this variation exceed 110% of the median variance\n",
    "    samples_lost_at = [i for i in range(1, len(df_dips_peaks_clean))\n",
    "                if ((df_dips_peaks_clean['samplesDiffMV'].iloc[i-1] < median_moving_var*1.1)\n",
    "                and (df_dips_peaks_clean['samplesDiffMV'].iloc[i]   >= median_moving_var*1.1))]\n",
    "    df_samples_lost_at = df_dips_peaks_clean.iloc[samples_lost_at].copy()\n",
    "    \n",
    "    # Determine a list of intervals where the dips and peaks are stable based on the points where samples are lost,\n",
    "    # adding the first and last samples as endpoints\n",
    "    firstTime = df['time'].iloc[0]\n",
    "    lastTime = df['time'].iloc[-1]\n",
    "    segments = pd.DataFrame(zip([firstTime] + list(df_samples_lost_at['time']),\n",
    "                                 list(df_samples_lost_at['time'])+[max(df_dips_peaks_clean['time'])]))\n",
    "    segments.columns = ['from', 'to']\n",
    "\n",
    "    # Calculate the Mean value for dips and peaks over each interval\n",
    "    def getMeanDipsPeaksForInterval(row, dippeak):\n",
    "        samples =  df_dips_peaks_clean[df_dips_peaks_clean.time.between(row['from'], row['to']) \n",
    "                                        & (df_dips_peaks_clean.samplesDiffMV < median_moving_var*1.1)\n",
    "                                        & (df_dips_peaks_clean.dippeak==dippeak)]['samplesDiff']\n",
    "        return statistics.mean(samples) if len(samples) > 0 else np.NaN\n",
    "    segments['avg_peak'] = segments.apply(lambda row: getMeanDipsPeaksForInterval(row, 'peak'), axis=1)\n",
    "    segments['avg_dip'] = segments.apply(lambda row: getMeanDipsPeaksForInterval(row, 'dip'), axis=1)\n",
    "\n",
    "    # Calculate the required adjustment based on the difference in mean peaks and dips for all but the first interval\n",
    "    segments.insert(0, 'adjustment', 0)\n",
    "    segments.insert(0, 'cumulative_adjustment', 0)\n",
    "    adjustmentSoFar = 0\n",
    "    for index, _ in segments.iterrows():\n",
    "        diffs = [segments['avg_peak'].iloc[0] - segments['avg_peak'][index] - adjustmentSoFar,\n",
    "                segments['avg_dip'].iloc[0] - segments['avg_dip'][index] - adjustmentSoFar]\n",
    "        diffs = [i for i in diffs if not math.isnan(i)]\n",
    "        if len(diffs) > 0:\n",
    "            adjustment = int(statistics.mean(diffs))\n",
    "            if adjustment > 0:\n",
    "                segments.at[index, 'adjustment'] = adjustment\n",
    "                adjustmentSoFar += adjustment\n",
    "            segments.at[index, 'cumulative_adjustment'] = adjustmentSoFar\n",
    "\n",
    "\n",
    "    if showGraph:\n",
    "        print(f'sr: {data[\"sr\"]}')\n",
    "        print(f'median moving var: {median_moving_var}')\n",
    "        bokeh.io.output_notebook()\n",
    "        p = bokeh.plotting.figure()\n",
    "        p.xaxis.formatter = datetimeTickFormatter\n",
    "        p.xaxis.major_label_orientation = math.pi/2\n",
    "\n",
    "        # Plot these points, which will contain some outlier for case 1) above\n",
    "        p.scatter(x='time', y='samplesDiff', source=df_dips_peaks, color=\"yellow\")\n",
    "        p.line(x='time', y='samplesDiffMV', source=df_dips_peaks, color=\"yellow\")\n",
    "        \n",
    "        # Then plot the dips and peaks again for the cleaned data\n",
    "        p.scatter(x='time', y='samplesDiff', source=df_dips_peaks_clean, color=\"blue\")\n",
    "        p.line(x='time', y='samplesDiffMV', source=df_dips_peaks_clean, color=\"blue\")\n",
    "        \n",
    "        # Plot the points where data is lost in red\n",
    "        p.scatter(x='time', y='samplesDiffMV', source=df_samples_lost_at, color=\"red\")\n",
    "    \n",
    "        # Create new dataframe for visualisation only to show the dips and peaks after adjustment\n",
    "        df_adjusted = df_dips_peaks_clean.copy()\n",
    "        df_adjusted['adjusted'] = df_dips_peaks_clean['samplesDiff'].copy()\n",
    "        segment_index = 0\n",
    "        for index, _ in df_adjusted.iterrows():\n",
    "            if segment_index + 1 < len(segments) and segments['from'].iloc[segment_index+1] == df_adjusted['time'].loc[index]:\n",
    "                segment_index += 1\n",
    "            df_adjusted.at[index, 'adjusted'] += segments['cumulative_adjustment'].iloc[segment_index]\n",
    "        p.scatter(x='time', y='adjusted', source=df_adjusted, color=\"green\")\n",
    "\n",
    "        bokeh.plotting.show(p)\n",
    "#         print(segments)\n",
    "\n",
    "    return segments\n",
    "\n",
    "def adjustForMissingSamples(data, showGraph=False):\n",
    "    segments = getDroppedSamplesTimeAndLength(data, showGraph)\n",
    "    def getSampleIndex(time):\n",
    "        starttime = segments.iloc[0]['from']\n",
    "        return int((time - starttime) * data['sr'] / 1000)\n",
    "\n",
    "    new_wav = data['wav'][0:getSampleIndex(segments.iloc[0]['to'])]\n",
    "    for i in range(1,len(segments)):\n",
    "        new_wav = np.append(new_wav, [0] * int(segments.iloc[i]['adjustment']))\n",
    "        new_wav = np.append(new_wav, data['wav'][getSampleIndex(segments.iloc[i]['from']):getSampleIndex(segments.iloc[i]['to'])])\n",
    "    new_wav = np.append(new_wav, data['wav'][getSampleIndex(segments.iloc[-1]['to']):len(data['wav'])])\n",
    "    data['adjusted_wav'] = new_wav\n",
    "    return data\n",
    "\n",
    "def getDataAndAdjustForMissingSamples(directory):\n",
    "    data = getData(directory)\n",
    "    adjustForMissingSamples(data)\n",
    "    return data\n",
    "\n",
    "def getKeystrokes(data, sync_adjustment=0, sample_duration=0, min_peak_value=0.01):\n",
    "    adjustForMissingSamples(data, True)\n",
    "    starttime = data['starttime_recorder_start_event']\n",
    "    down_event_times = [(e[1]-starttime+sync_adjustment, e[3]) for e in data['down_events']]\n",
    "    firstKeydown = down_event_times[0][0]\n",
    "    sr = data['sr']\n",
    "    srms = sr/1000\n",
    "    wav = data['adjusted_wav']\n",
    "\n",
    "    print(f'Audio starts at {starttime}')\n",
    "    print(f'First keydown event after {firstKeydown} ms')\n",
    "    plotBokeh(getDataSubset(data, max(firstKeydown-500, 0), 2000), sync_adjustment, whichWav='adjusted_wav')\n",
    "    \n",
    "    samples = [(key, wav[int(time*srms):int((time+sample_duration)*srms)]) for (time, key) in down_event_times]\n",
    "    filtered_samples = [(key, wav) for (key, wav) in samples if max(wav) >= min_peak_value]\n",
    "    print (f'Using {len(filtered_samples)} out of {len(samples)} keystrokes')\n",
    "    \n",
    "    return [k for (k, _) in filtered_samples], [w for (_, w) in filtered_samples]\n",
    "\n",
    "def addKeystrokes(data, sync_adjustment, sample_duration, min_peak_value):\n",
    "    labels, wavs = getKeystrokes(data, sync_adjustment, sample_duration, min_peak_value)\n",
    "    data['keystroke_labels'] = labels\n",
    "    data['keystroke_wavs'] = wavs\n",
    "\n",
    "def normaliseFeatures(features):\n",
    "    (nr_keystrokes, nr_mfcc_features, nr_frames) = features.shape\n",
    "    print (f'Normalising {nr_keystrokes} keystrokes, with {nr_mfcc_features} features and {nr_frames} frames per sample')\n",
    "    \n",
    "    # features have shape (nr_keystrokes, nr_mfcc_features, nr_frames)\n",
    "    # first move nr_mfcc_features axis to the front so we get (nr_mfcc_features, nr_keystrokes, nr_frames)\n",
    "    X1 = np.moveaxis(features, 1, 0)\n",
    "    # then reshape to make it a 2D (nr_mfcc_features, nr_keystrokes*nr_frames) array\n",
    "    X2 = X1.reshape(nr_mfcc_features, nr_keystrokes*nr_frames)\n",
    "    # Normalise\n",
    "    X3 = scale(X2, axis=1, with_mean=True, with_std=True, copy=True)\n",
    "    # back to (nr_mfcc_features, nr_keystrokes, nr_frames)\n",
    "    X4 = X3.reshape(nr_mfcc_features, nr_keystrokes, nr_frames)\n",
    "    # back to (nr_keystrokes, nr_mfcc_features, nr_frames)\n",
    "    X5 = np.moveaxis(X4, 0, 1)\n",
    "    \n",
    "    return X5\n",
    "\n",
    "def filterLabels(labels, keep=['Space', 'Backspace', 'Enter']):\n",
    "    return [label if label in keep else 'Other' for label in labels]\n",
    "\n",
    "def printListGroupPercentages(l):\n",
    "    percentages = [(k, 100*len(list(g))/len(l)) for k, g in groupby(sorted(l), lambda x: x)]\n",
    "    percentages = sorted(percentages, key=lambda x: x[1], reverse=True)\n",
    "    return ', '.join([f\"'{key}' {'%d' % percentage}%\" for (key, percentage) in percentages])\n",
    "\n",
    "def printClusteringResult(clustering, labels, method=None):\n",
    "    if method != None:\n",
    "        print (f'Clustering results using {method}')\n",
    "    print (f'homogeneity_completeness_v_measure: {homogeneity_completeness_v_measure(labels, clustering)}')\n",
    "    def cluster(x):\n",
    "        return x[0]\n",
    "    def label(x):\n",
    "        return x[1]\n",
    "\n",
    "    print (f'by cluster')\n",
    "    data=list(zip(clustering, labels))\n",
    "    data = sorted(data, key=cluster)\n",
    "    for k, g in groupby(data, cluster):\n",
    "        group = [label(x) for x in g]\n",
    "        group.sort()\n",
    "        print (f'{k}: {printListGroupPercentages(group)}')\n",
    "    print (f'by key')\n",
    "    data=list(zip(clustering, labels))\n",
    "    data = sorted(data, key=label)\n",
    "    for k, g in groupby(data, label):\n",
    "        group = [cluster(x) for x in g]\n",
    "        group.sort()\n",
    "        print (f'{k}: {printListGroupPercentages(group)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitech_step1_fast = getDataAndAdjustForMissingSamples('logitech-fast/niels-step_1-1617765899871')\n",
    "logitech_step1_slow = getDataAndAdjustForMissingSamples('logitech-slow/niels-step_1-1617765658270')\n",
    "lenovo_slow = getDataAndAdjustForMissingSamples('lenovo-slow-easy/niels-step_5-1617952576650')\n",
    "lenovo_slow2 = getDataAndAdjustForMissingSamples('lenovo-slow-easy/niels-step_5-1618197371437')\n",
    "lenovo_hard = getDataAndAdjustForMissingSamples('lenovo-hard/niels-step_1-1618199054005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addKeystrokes(lenovo_slow, 50, 100, 0.01)\n",
    "# addKeystrokes(lenovo_slow2, 125, 100, 0.01)\n",
    "# addKeystrokes(logitech_step1_fast, 50, 100, 0.01)\n",
    "addKeystrokes(logitech_step1_slow, 60, 50, 0.01)\n",
    "# addKeystrokes(lenovo_hard, 50, 100, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plotBokeh(getDataSubset(logitech_step1_slow, 1000, 2000), 50, whichWav='adjusted_wav')\n",
    "plotBokeh(getDataSubset(logitech_step1_slow, 200000, 10000), 50, whichWav='adjusted_wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(logitech_step1_slow['wav'])/logitech_step1_slow['sr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(logitech_step1_slow['keystroke_wavs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getFeatures: mfcc\n",
      "getFeatures: Normalise\n",
      "Normalising 424 keystrokes, with 32 features and 21 frames per sample\n",
      "getFeatures: Get max\n",
      "getFeatures: Get mean\n",
      "getFeatures: Get stddev\n",
      "getFeatures: Done\n",
      "Concatenating these features: ['mfcc_max', 'mfcc_mean', 'mfcc_stddev']\n",
      "Resulting shape: (424, 96)\n"
     ]
    }
   ],
   "source": [
    "def addFeatures(data):\n",
    "    sr = data['sr']\n",
    "    wavs = data['keystroke_wavs']\n",
    "    srms = int(sr/1000)\n",
    "\n",
    "    hop_length = int(2.5*srms)\n",
    "    window_length = int(10*srms)\n",
    "    \n",
    "    print('getFeatures: mfcc')\n",
    "    data['mfcc_features'] = np.array([librosa.feature.mfcc(wav, sr, n_mfcc=32, win_length=window_length, hop_length=hop_length) for wav in wavs])\n",
    "    print('getFeatures: Normalise')\n",
    "    data['normalised_mfcc_features'] = normaliseFeatures(data['mfcc_features'])\n",
    "    print('getFeatures: Get max')\n",
    "    data['mfcc_max'] = np.apply_along_axis(max, 2, data['normalised_mfcc_features'])\n",
    "    print('getFeatures: Get mean')\n",
    "    data['mfcc_mean'] = np.apply_along_axis(statistics.mean, 2, data['normalised_mfcc_features'])\n",
    "    print('getFeatures: Get stddev')\n",
    "    data['mfcc_stddev'] = np.apply_along_axis(statistics.stdev, 2, data['normalised_mfcc_features'])\n",
    "    print('getFeatures: Done')\n",
    "\n",
    "    \n",
    "def getConcatenatedFeatures(data, features):\n",
    "    missing_features = [x for x in features if x not in data.keys()]\n",
    "    if len(missing_features) > 0:\n",
    "        print (f'Missing features: {\", \".join(missing_features)}. Calling addFeatures to add them.')\n",
    "        addFeatures(data)\n",
    "    print (f'Concatenating these features: {features}')\n",
    "    c = np.concatenate([data[feature] for feature in features], axis=1)\n",
    "    print (f'Resulting shape: {c.shape}')\n",
    "    return c\n",
    "\n",
    "addFeatures(logitech_step1_slow)\n",
    "features = getConcatenatedFeatures(logitech_step1_slow, ['mfcc_max', 'mfcc_mean', 'mfcc_stddev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitech_step1_slow['mfcc_max'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNumberOfClusters(features):\n",
    "    x = list(range(2, 40))\n",
    "    scores = []\n",
    "    for n_clusters in tqdm(x):\n",
    "        #     n_clusters = 500\n",
    "        kmeans = sklearn.cluster.KMeans(n_clusters)\n",
    "        kmeans.fit(features)\n",
    "        kmeans_score = kmeans.score(features)\n",
    "        clustering = kmeans.predict(features)\n",
    "        kmeans_silhouette_score = silhouette_score(features, clustering)\n",
    "\n",
    "        gm = sklearn.mixture.GaussianMixture(n_clusters)\n",
    "        gm.fit(features)\n",
    "        gm_score = gm.score(features)\n",
    "        gm_bic_score = gm.bic(features)\n",
    "        \n",
    "        scores.append((kmeans_score, kmeans_silhouette_score, gm_score, gm_bic_score))\n",
    "    return x, scores\n",
    "number_of_clusters,scores = findNumberOfClusters(getConcatenatedFeatures(logitech_step1_slow, ['mfcc_max', 'mfcc_mean', 'mfcc_stddev']))\n",
    "\n",
    "for (i, s) in enumerate(['kmeans_score', 'kmeans_silhouette_score', 'gm_score', 'gm_bic_score']):\n",
    "    plt.figure()\n",
    "    plt.title(s)\n",
    "    plt.scatter(number_of_clusters, [x[i] for x in scores])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424\n",
      "Concatenating these features: ['mfcc_mean', 'mfcc_stddev']\n",
      "Resulting shape: (424, 64)\n",
      "Clustering results using SpectralClustering\n",
      "homogeneity_completeness_v_measure: (0.05687324609258826, 0.07722676040043476, 0.06550538906074985)\n",
      "by cluster\n",
      "0: 'Other' 70%, 'Space' 15%, 'KeyE' 11%, 'Backspace' 1%\n",
      "1: 'Space' 90%, 'Other' 9%\n",
      "2: 'Other' 100%\n",
      "3: 'Other' 100%\n",
      "4: 'Other' 69%, 'Space' 25%, 'KeyE' 4%\n",
      "by key\n",
      "Backspace: '0' 100%\n",
      "KeyE: '0' 93%, '4' 6%\n",
      "Other: '0' 82%, '4' 14%, '2' 2%, '3' 0%, '1' 0%\n",
      "Space: '0' 67%, '4' 20%, '1' 12%\n",
      "Clustering results using k_means\n",
      "homogeneity_completeness_v_measure: (0.4098899032549833, 0.22195628580553553, 0.28797401041838827)\n",
      "by cluster\n",
      "0: 'Other' 82%, 'KeyE' 16%, 'Backspace' 1%\n",
      "1: 'Other' 86%, 'KeyE' 11%, 'Backspace' 2%\n",
      "2: 'Other' 86%, 'KeyE' 6%, 'Backspace' 4%, 'Space' 1%\n",
      "3: 'Space' 93%, 'Other' 6%\n",
      "4: 'Other' 77%, 'KeyE' 12%, 'Space' 10%\n",
      "by key\n",
      "Backspace: '2' 50%, '1' 33%, '0' 16%\n",
      "KeyE: '0' 34%, '4' 32%, '1' 23%, '2' 9%\n",
      "Other: '4' 29%, '0' 25%, '1' 25%, '2' 17%, '3' 1%\n",
      "Space: '3' 83%, '4' 15%, '2' 1%\n",
      "Clustering results using GaussianMixture\n",
      "homogeneity_completeness_v_measure: (0.36749763870950425, 0.19903736551680581, 0.2582215089861158)\n",
      "by cluster\n",
      "0: 'Other' 85%, 'KeyE' 11%, 'Backspace' 1%, 'Space' 0%\n",
      "1: 'Other' 64%, 'Space' 24%, 'KeyE' 7%, 'Backspace' 3%\n",
      "2: 'Other' 81%, 'KeyE' 16%, 'Backspace' 1%\n",
      "3: 'Other' 86%, 'KeyE' 11%, 'Space' 2%\n",
      "4: 'Space' 93%, 'Other' 6%\n",
      "by key\n",
      "Backspace: '1' 50%, '0' 33%, '2' 16%\n",
      "KeyE: '0' 32%, '2' 30%, '3' 23%, '1' 13%\n",
      "Other: '0' 33%, '3' 25%, '2' 21%, '1' 17%, '4' 1%\n",
      "Space: '4' 71%, '1' 25%, '3' 2%, '0' 1%\n"
     ]
    }
   ],
   "source": [
    "def tmp(data):\n",
    "    labels = data['keystroke_labels']\n",
    "    print(len(labels))\n",
    "    features = getConcatenatedFeatures(data, ['mfcc_mean', 'mfcc_stddev'])\n",
    "    filtered_labels = filterLabels(labels, keep = ['Space', 'Backspace', 'KeyE'])\n",
    "    n_clusters = len(set(filtered_labels)) + 1\n",
    "\n",
    "    clustering=sklearn.cluster.SpectralClustering(n_clusters).fit(features).labels_\n",
    "    printClusteringResult(clustering, filtered_labels, 'SpectralClustering')\n",
    "\n",
    "    clustering=sklearn.cluster.k_means(features, n_clusters=n_clusters)[1]\n",
    "    printClusteringResult(clustering, filtered_labels, 'k_means')\n",
    "\n",
    "    gm = sklearn.mixture.GaussianMixture(n_clusters)\n",
    "    gm.fit(features)\n",
    "    clustering = gm.predict(features)\n",
    "    printClusteringResult(clustering, filtered_labels, 'GaussianMixture')\n",
    "tmp(logitech_step1_slow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'normalised_mfcc_features'\n",
    "\n",
    "spaces = [w for (w, l) in zip(logitech_step1_slow[f], logitech_step1_slow['keystroke_labels']) if l=='Space']\n",
    "keyEs = [w for (w, l) in zip(logitech_step1_slow[f], logitech_step1_slow['keystroke_labels']) if l=='KeyE']\n",
    "print(f'number of spaces: {len(spaces)}, number of Es: {len(keyEs)}')\n",
    "\n",
    "\n",
    "def dtw_distance(key1, key2):\n",
    "    D, wp = librosa.sequence.dtw(key1, key2)\n",
    "    best_cost = D[wp[-1, 0], wp[-1, 1]]\n",
    "    return best_cost\n",
    "\n",
    "\n",
    "dist_spaces = []\n",
    "dist_keyEs = []\n",
    "dist_spacesToKeyEs = []\n",
    "\n",
    "for i in range(len(spaces)):\n",
    "    for j in range(i+1, len(spaces)):\n",
    "        dist_spaces.append(dtw_distance(spaces[i], spaces[j]))\n",
    "for i in range(len(keyEs)):\n",
    "    for j in range(i+1, len(keyEs)):\n",
    "        dist_keyEs.append(dtw_distance(keyEs[i], keyEs[j]))\n",
    "for i in range(len(spaces)):\n",
    "    for j in range(len(keyEs)):\n",
    "        dist_spacesToKeyEs.append(dtw_distance(spaces[i], keyEs[j]))\n",
    "        \n",
    "print(np.mean(dist_spaces))\n",
    "print(np.mean(dist_keyEs))\n",
    "print(np.mean(dist_spacesToKeyEs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "librosa.sequence.dtw([[0,1,0,0,0,0],\n",
    "                      [0,1,0,0,0,0]], \n",
    "                     [[0,0,1,0,0,0],\n",
    "                      [0,0,1,0,0,0]], return_steps=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = logitech_step1_slow['keystroke_wavs'][0]\n",
    "print( librosa.feature.spectral_centroid(wav, 48000, win_length=1000, hop_length=2).shape )\n",
    "print( librosa.feature.chroma_stft(wav, 48000, win_length=1000, hop_length=2).shape )\n",
    "print( librosa.feature.zero_crossing_rate(wav, frame_length=1000, hop_length=2).shape )\n",
    "print( list(librosa.feature.zero_crossing_rate(wav, frame_length=2, hop_length=2)[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getDroppedSamplesTimeAndLength(logitech_step1_fast, True)\n",
    "# getDroppedSamplesTimeAndLength(logitech_step1_slow, True)\n",
    "# plotBokeh(getDataSubset(logitech_step1_slow, 1800, 3000), 50)\n",
    "# plotBokeh(getDataSubset(logitech_step1_slow, 142000, 2000), 50, whichWav='wav')\n",
    "# plotBokeh(getDataSubset(logitech_step1_slow, 142000, 2000), 50, whichWav='adjusted_wav')\n",
    "# plotBokeh(getDataSubset(logitech_step1_slow, 182000, 2000), 50, whichWav='wav')\n",
    "# plotBokeh(getDataSubset(logitech_step1_slow, 182000, 2000), 50, whichWav='adjusted_wav')\n",
    "# plotBokeh(getDataSubset(logitech_step1_slow, 0, 2000), 50, whichWav='wav')\n",
    "# getDroppedSamplesTimeAndLength(lenovo_slow, True)\n",
    "\n",
    "def printKeyStroke(key, wav, sr):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.ylim((-0.4,0.4))\n",
    "    librosa.display.waveplot(wav, sr=sr, alpha=0.1)\n",
    "    plt.title(key)\n",
    "for (key, wav) in list(zip(logitech_step1_slow['keystroke_labels'], logitech_step1_slow['keystroke_wavs']))[160:170]:\n",
    "    printKeyStroke(key, wav, 48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
