{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import mysql.connector as mysql\n",
    "import bokeh.plotting\n",
    "import bokeh.models\n",
    "import bokeh.io\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import statistics\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimeTickFormatter = bokeh.models.DatetimeTickFormatter(\n",
    "    microseconds = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    milliseconds = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    seconds = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    minsec = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    minutes = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    hourmin = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    hours = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    days = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    months = ['%d-%m    %H:%M:%S.%3N'],\n",
    "    years = ['%d-%m    %H:%M:%S.%3N'])\n",
    "\n",
    "def getCombinedWavs(directory, use_directory_starttime=True):\n",
    "    nr = 0\n",
    "    sr = None\n",
    "    y = None\n",
    "    files = os.listdir(directory)\n",
    "    files.sort()\n",
    "    last_endtime = None\n",
    "    total_gap = 0\n",
    "    for filename in files:\n",
    "        fullfilename = f'{directory}/{filename}'\n",
    "        y_part, sr_part = librosa.load(fullfilename, sr=None)\n",
    "        \n",
    "        file_end = int(re.search(\"^\\d*-(\\d*)\\.wav\", filename).group(1))\n",
    "        file_start = file_end - int(len(y_part) * 1000 / sr_part)\n",
    "        if sr == None:\n",
    "            sr = sr_part\n",
    "            y = y_part\n",
    "            end = int(re.search(\"^\\d*-(\\d*)\\.wav\", files[0]).group(1))\n",
    "            if use_directory_starttime:\n",
    "                unixtime_start = int(re.search(\".*-(\\d*)\", directory).group(1))\n",
    "            else:\n",
    "                unixtime_start = file_start            \n",
    "        else:\n",
    "            if sr != sr_part:\n",
    "                raise Exception(\"Sampling rate mismatch\")\n",
    "            y = np.concatenate([y, y_part])\n",
    "        nr += 1\n",
    "        if last_endtime == None:\n",
    "            print (f'part {\"%3d\" % nr}, {\"%7d\" % len(y_part)} samples from unixtime {file_start} to {file_end}.')\n",
    "        else:\n",
    "            gap = file_start - last_endtime\n",
    "            total_gap += gap\n",
    "            print (f'part {\"%3d\" % nr}, {\"%7d\" % len(y_part)} samples from unixtime {file_start} to {file_end}. Gap: {gap}. Total gap: {total_gap}')\n",
    "        last_endtime = file_end\n",
    "        \n",
    "    unixtime_end = int(unixtime_start + len(y) * 1000 / sr)\n",
    "    print (f'total:    {\"%7d\" % len(y)} samples from unixtime {unixtime_start} to {unixtime_end}')\n",
    "    print (f'Read {nr} parts from {directory}. {y.shape[0]} samples: {\"%.1f\" % (y.shape[0]/sr)} seconds at {sr} samples/sec, starting at unixtime {unixtime_start}')\n",
    "    return y, sr, unixtime_start\n",
    "\n",
    "def queryDb(query, args=()):\n",
    "    try:\n",
    "        conn = mysql.connect(user=\"root\",\n",
    "                             password=\"1234\",\n",
    "                             host=\"localhost\",\n",
    "                             port=3306,\n",
    "                             database=\"imagedescription\")\n",
    "    except mysql.Error as e:\n",
    "        print(f\"Error connecting to MariaDB Platform: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Get Cursor\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(query, args)\n",
    "    data = [x for x in cur]\n",
    "    cur.close()\n",
    "    return data\n",
    "\n",
    "def getSteps(s):\n",
    "    s = list(s)\n",
    "    return [cur-prev for (cur, prev) in zip(s, [s[0]]+s)]\n",
    "\n",
    "def getData(directory, use_directory_starttime=True):\n",
    "    wav, sr, audio_unixtime_ms = getCombinedWavs(directory, use_directory_starttime)\n",
    "    audio_length_ms = int(len(wav) / sr * 1000)\n",
    "\n",
    "    print (f'Recording starts at unix time {audio_unixtime_ms} and lasts until {audio_unixtime_ms + audio_length_ms}')\n",
    "\n",
    "    events = queryDb(\"SELECT time, unix_time, type, data \"\n",
    "                     \"FROM logger_traces \"\n",
    "                     \"WHERE type IN ('keydown', 'keyup') \"\n",
    "                     \"AND user_id = %s \"\n",
    "                     \"AND unix_time BETWEEN %s AND %s\",\n",
    "                    (8,\n",
    "                        audio_unixtime_ms,\n",
    "                        audio_unixtime_ms + audio_length_ms))\n",
    "\n",
    "    up_events = [x for x in events if x[2]=='keyup']\n",
    "    down_events = [x for x in events if x[2]=='keydown']\n",
    "\n",
    "    print(f'Read {len(up_events)} keyup events and {len(down_events)} keydown events.')\n",
    "\n",
    "    return {\n",
    "        'wav': wav,\n",
    "        'sr': sr,\n",
    "        'audio_unixtime_ms': audio_unixtime_ms,\n",
    "        'up_events': up_events,\n",
    "        'down_events': down_events\n",
    "    }\n",
    "\n",
    "def plotMatplotlib(data):\n",
    "    wav=data['wav']\n",
    "    sr=data['sr']\n",
    "    audio_unixtime_ms=data['audio_unixtime_ms']\n",
    "    up_events=data['up_events']\n",
    "    down_events=data['down_events']\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.ylim((0,0.02))\n",
    "    librosa.display.waveplot(wav, sr=sr, alpha=0.1)\n",
    "    plt.scatter([(x[1]-audio_unixtime_ms)/1000 for x in down_events], [0 for _ in down_events])\n",
    "    plt.scatter([(x[1]-audio_unixtime_ms)/1000 for x in up_events], [0.01 for _ in up_events])\n",
    "\n",
    "def plotBokeh(data, adjust_ms=0):\n",
    "    wav=data['wav']\n",
    "    sr=data['sr']\n",
    "    audio_unixtime_ms=data['audio_unixtime_ms']\n",
    "    up_events=data['up_events']\n",
    "    down_events=data['down_events']\n",
    "    \n",
    "    s_sound = pd.Series(data=wav, index=range(len(wav)))\n",
    "    df_sound = pd.DataFrame(s_sound)\n",
    "    df_sound.reset_index(inplace=True)\n",
    "    df_sound.columns = ['Index', 'wav']\n",
    "    df_sound['unixtime'] = df_sound['Index'].apply(lambda x: audio_unixtime_ms + x * 1000 / sr)\n",
    "    df_sound['time'] = df_sound['Index'].apply(lambda x: datetime.datetime.utcfromtimestamp(int(x / 1000)))\n",
    "\n",
    "    bokeh.io.output_notebook()\n",
    "    p = bokeh.plotting.figure()\n",
    "    p.xaxis.formatter = datetimeTickFormatter\n",
    "    p.xaxis.major_label_orientation = math.pi/2\n",
    "    p.line(x='unixtime', y='wav', source=df_sound)\n",
    "    \n",
    "    def plotEvents(events, colour=\"black\", y_offset=0):\n",
    "        df = pd.DataFrame()\n",
    "        df['x'] = [e[1]+adjust_ms for e  in events]\n",
    "        df['y'] = [0.015]*len(events)\n",
    "        df['text'] = [e[3][3:] if e[3].startswith('Key') else e[3] for e in events]\n",
    "        source = bokeh.models.ColumnDataSource(df)\n",
    "\n",
    "        p.scatter(x='x', y='y', source=source, size=10, color=colour, alpha=0.5)\n",
    "        p.add_layout(bokeh.models.LabelSet(x='x', y='y', text='text', source=source, x_offset=5, y_offset=y_offset, render_mode='canvas', angle=math.pi/2, text_color=colour))\n",
    "    \n",
    "    plotEvents(down_events, \"green\", 20)\n",
    "    plotEvents(up_events, \"red\", -120)\n",
    "       \n",
    "    bokeh.plotting.show(p)\n",
    "    \n",
    "def diffPeekAmplAndKeyDown(directory):\n",
    "    data = getData(directory)\n",
    "    down_event = data['down_events'][0][1]\n",
    "    max_index = np.argmax(data['wav'])\n",
    "    max_time = data['audio_unixtime_ms'] + int(max_index * 1000 / data['sr'])\n",
    "    print (f'{directory} max ampl at {max_time}, keydown at {down_event}, difference {max_time-down_event}')\n",
    "\n",
    "def getDataSubset(data, offset_ms, length_ms=2000):\n",
    "    sr = data['sr']\n",
    "    starttime = data['audio_unixtime_ms'] + offset_ms\n",
    "    subset_wav = data['wav'][int(offset_ms*sr/1000):int((offset_ms+length_ms)*sr/1000)]\n",
    "    subset_up_events = [e for e in data['up_events'] if starttime < e[1] and e[1] < (starttime+length_ms)]\n",
    "    subset_down_events = [e for e in data['down_events'] if starttime < e[1] and e[1] < (starttime+length_ms)]\n",
    "    return {\n",
    "        'wav': subset_wav,\n",
    "        'sr': sr,\n",
    "        'audio_unixtime_ms': starttime,\n",
    "        'up_events': subset_up_events,\n",
    "        'down_events': subset_down_events\n",
    "    }\n",
    "    \n",
    "def aap(x, adjust_ms=0):\n",
    "    data=getData(f'../web/data/videos/{x}')\n",
    "    plotBokeh(data, adjust_ms=adjust_ms)\n",
    "    \n",
    "    wav=data['wav']\n",
    "    sr=data['sr']\n",
    "    s=librosa.stft(y=wav, hop_length=int(sr/1000))\n",
    "    data['wav'] = abs(s.sum(axis=0))\n",
    "    data['sr'] = 1000\n",
    "    plotBokeh(data)\n",
    "\n",
    "\n",
    "def moving_ranges(data, context):\n",
    "    data2 = list(data)\n",
    "    data3 = [data2[0]]*(context) + data2\n",
    "    return [data3[i:i+1+context] for i in range(len(data2))]\n",
    "def moving_ranges_f(data, context, f):\n",
    "    ranges = moving_ranges(data, context)\n",
    "    return [f(x) for x in ranges]\n",
    "def moving_average(x, context):\n",
    "    return moving_ranges_f(x, context, statistics.mean)\n",
    "def moving_var(x, context):\n",
    "    return moving_ranges_f(x, context, lambda r: max(r)-min(r))\n",
    "\n",
    "def getAllTraceEvents(directory):\n",
    "    starttime=int(re.search(\".*-(\\d*)\", directory).group(1))\n",
    "    return queryDb(f\"\"\"select * from logger_traces where uuid = (select uuid from logger_traces lt where type='startaudio' and data like '%{starttime}') order by id\"\"\", ())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate where to add dummy values to compensate for occassionally dropped samples and keep the audio in sync with database\n",
    "def getRecorderMarksFromDatabase(directory):\n",
    "    events = getAllTraceEvents(directory)\n",
    "    timeAndBufferSize = [(x[6], x[8]) for x in events if x[7] == 'recorder-mark'][1:]\n",
    "    starttime=timeAndBufferSize[0][0]\n",
    "    startsize=timeAndBufferSize[0][1]\n",
    "    times = [t for (t, s) in timeAndBufferSize]\n",
    "    samplesDiff = [(s-startsize)-((t-starttime)*48000/1000) for (t, s) in timeAndBufferSize]\n",
    "    msSinceLastSample=getSteps(times)\n",
    "    df = pd.DataFrame()\n",
    "    df['time']=times\n",
    "    df['samplesDiff']=samplesDiff\n",
    "    df['msSinceLastSample']=msSinceLastSample\n",
    "    return df\n",
    "\n",
    "def getDroppedSamplesTimeAndLength(directory, showGraph=False):\n",
    "    CONTEXT=4\n",
    "    df = getRecorderMarksFromDatabase(directory)\n",
    "    \n",
    "    # The difference between the number of samples in the data, and the expected number based on sampling rate and during\n",
    "    # varies over time. Samples don't get delivered exactly on time, but usually the difference stays within a clear bound.\n",
    "    #\n",
    "    # Two things may occur that break this pattern:\n",
    "    #  1) occassionally some samples get queued up and delivered late, so we see a temporary increase in the difference which quickly gets corrected when the samples do arrive\n",
    "    #  2) on other occassions samples really get dropped and we see the difference increase permanently\n",
    "    #\n",
    "    # To keep keystrokes in sync, the first case doesn't matter since later we will only use the samples and don't care when they were received,\n",
    "    # but for the second case we want to insert some dummy samples to make sure the samples after that stay in sync.\n",
    "    \n",
    "    # First find the peaks and dips in the oscilating sample difference\n",
    "    peaks = find_peaks(df['samplesDiff'])[0]\n",
    "    dips = find_peaks([-x for x in df['samplesDiff']])[0]\n",
    "    dips_and_peaks = np.concatenate((dips, peaks))\n",
    "    dips_and_peaks.sort()\n",
    "    df_dips_peaks = df.iloc[dips_and_peaks].copy()\n",
    "    df_dips_peaks['dippeak'] = ['dip' if x in dips else 'peak' for x in df_dips_peaks.index]\n",
    "    df_dips_peaks['samplesDiffMV'] = moving_var(df_dips_peaks['samplesDiff'], CONTEXT)\n",
    "\n",
    "    # Filter out these outliers based on the max difference in the samplesDiff column over a trailing window of CONTEXT samples\n",
    "    median_moving_var = statistics.median(moving_var(df_dips_peaks['samplesDiff'], CONTEXT))    \n",
    "    not_outliers = [i for i in range(len(dips_and_peaks)-1)\n",
    "                    if df_dips_peaks['samplesDiff'].iloc[i+1] - df_dips_peaks['samplesDiff'].iloc[i] < 1.5*median_moving_var]\n",
    "    df_dips_peaks_clean = df_dips_peaks.iloc[not_outliers].copy()\n",
    "    # recalculate this since it will have changed after removing the outliers\n",
    "    df_dips_peaks_clean['samplesDiffMV'] = moving_var(df_dips_peaks_clean['samplesDiff'], CONTEXT)     \n",
    "\n",
    "    # We now want to find the segments of stable data, and calculate the number samples lost by comparing the average value for peaks and dips in two blocks\n",
    "    # The variation in sample difference is quite stable within a block, so we mark points where this variation exceed 110% of the median variance\n",
    "    samples_lost_at = [i for i in range(1, len(df_dips_peaks_clean))\n",
    "                if ((df_dips_peaks_clean['samplesDiffMV'].iloc[i-1] < median_moving_var*1.1)\n",
    "                and (df_dips_peaks_clean['samplesDiffMV'].iloc[i]   >= median_moving_var*1.1))]\n",
    "    df_samples_lost_at = df_dips_peaks_clean.iloc[samples_lost_at].copy()\n",
    "    \n",
    "    # Determine a list of intervals where the dips and peaks are stable based on the points where samples are lost,\n",
    "    # adding the first and last samples as endpoints\n",
    "    segments = pd.DataFrame(zip([min(df_dips_peaks_clean['time'])] + list(df_samples_lost_at['time']),\n",
    "                                 list(df_samples_lost_at['time'])+[max(df_dips_peaks_clean['time'])]))\n",
    "    segments.columns = ['from', 'to']\n",
    "\n",
    "    # Calculate the Mean value for dips and peaks over each interval\n",
    "    def getMeanDipsPeaksForInterval(row, dippeak):\n",
    "        samples =  df_dips_peaks_clean[df_dips_peaks_clean.time.between(row['from'], row['to']) \n",
    "                                        & (df_dips_peaks_clean.samplesDiffMV < median_moving_var*1.1)\n",
    "                                        & (df_dips_peaks_clean.dippeak==dippeak)]['samplesDiff']\n",
    "        return statistics.mean(samples) if len(samples) > 0 else np.NaN\n",
    "    segments['avg_peak'] = segments.apply(lambda row: getMeanDipsPeaksForInterval(row, 'peak'), axis=1)\n",
    "    segments['avg_dip'] = segments.apply(lambda row: getMeanDipsPeaksForInterval(row, 'dip'), axis=1)\n",
    "\n",
    "    # Calculate the required adjustment based on the difference in mean peaks and dips for all but the first interval\n",
    "    segments.insert(0, 'adjustment', 0)\n",
    "    adjustmentSoFar = 0\n",
    "    for index, _ in segments.iterrows():\n",
    "        diffs = [segments['avg_peak'].iloc[0] - segments['avg_peak'][index] - adjustmentSoFar,\n",
    "                segments['avg_dip'].iloc[0] - segments['avg_dip'][index] - adjustmentSoFar]\n",
    "        diffs = [i for i in diffs if not math.isnan(i)]\n",
    "        if len(diffs) > 0:\n",
    "            adjustment = statistics.mean(diffs)\n",
    "            if adjustment > 0:\n",
    "                adjustmentSoFar += adjustment\n",
    "                segments.at[index, 'adjustment']  = adjustment\n",
    "\n",
    "\n",
    "    if showGraph:\n",
    "        print(f'median moving var: {median_moving_var}')\n",
    "        bokeh.io.output_notebook()\n",
    "        p = bokeh.plotting.figure()\n",
    "        p.xaxis.formatter = datetimeTickFormatter\n",
    "        p.xaxis.major_label_orientation = math.pi/2\n",
    "\n",
    "        # Plot these points, which will contain some outlier for case 1) above\n",
    "        p.scatter(x='time', y='samplesDiff', source=df_dips_peaks, color=\"yellow\")\n",
    "        p.line(x='time', y='samplesDiffMV', source=df_dips_peaks, color=\"yellow\")\n",
    "        \n",
    "        # Then plot the dips and peaks again for the cleaned data\n",
    "        p.scatter(x='time', y='samplesDiff', source=df_dips_peaks_clean, color=\"blue\")\n",
    "        p.line(x='time', y='samplesDiffMV', source=df_dips_peaks_clean, color=\"blue\")\n",
    "        \n",
    "        # Plot the points where data is lost in red\n",
    "        p.scatter(x='time', y='samplesDiffMV', source=df_samples_lost_at, color=\"red\")\n",
    "    \n",
    "        # Create new dataframe for visualisation only to show the dips and peaks after adjustment\n",
    "        df_adjusted = df_dips_peaks_clean.copy()\n",
    "        df_adjusted['adjusted'] = df_dips_peaks_clean['samplesDiff'].copy()\n",
    "        for i in range(1, len(segments)):\n",
    "            from_time = segments['from'].iloc[i]\n",
    "            adjustment = segments['adjustment'].iloc[i]\n",
    "            # Sometimes we \n",
    "            if adjustment > 0:\n",
    "                for index, _ in df_adjusted.iterrows():\n",
    "                    if from_time <= df_adjusted.loc[index]['time']:\n",
    "                        df_adjusted.at[index, 'adjusted'] += adjustment\n",
    "        p.scatter(x='time', y='adjusted', source=df_adjusted, color=\"green\")\n",
    "\n",
    "        bokeh.plotting.show(p)\n",
    "        print(segments)\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=getDroppedSamplesTimeAndLength('niels-step_5-1617192257518', showGraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getDroppedSamplesTimeAndLength('niels-step_5-1617191574728', showGraph=True)\n",
    "getDroppedSamplesTimeAndLength('niels-step_5-1617187925912', showGraph=True)\n",
    "getDroppedSamplesTimeAndLength('niels-step_5-1617192257518', showGraph=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
